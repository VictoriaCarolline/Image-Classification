{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#importing all te req lib\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\nfrom keras.preprocessing import image\nimport numpy as np",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# dimensions of our images.\nimg_width, img_height = 150,150\n\n#defining the data directories\ntrain_data_dir= 'data/train'\nvalidation_data_dir= 'data/validation'\nn_training_sample= 400\nn_validation_sample= 100\nepochs=5\nbatch_size=10",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "if K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#defining the model\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Flatten(), \n  tf.keras.layers.Dense(128, activation=tf.nn.relu), \n  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n  tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)])",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#defining the optimizer and metrics\nmodel.compile(optimizer = tf.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary')\n\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=n_training_sample // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=n_validation_sample // batch_size)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found 800 images belonging to 2 classes.\nFound 200 images belonging to 2 classes.\nEpoch 1/5\n40/40 [==============================] - 223s 6s/step - loss: 0.9817 - accuracy: 0.5125 - val_loss: 0.6931 - val_accuracy: 0.5500\nEpoch 2/5\n16/40 [===========>..................] - ETA: 1:06 - loss: 0.6931 - accuracy: 0.4875",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#testing the model\npred= image.load_img('data/test/cat.4001.jpg', target_size=(150,150))\npred=image.img_to_array(pred)\npred= np.expand_dims(pred, axis=0)\nresult= model.predict(pred)\nprint(result)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[1. 1.]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "if result[0][0]==1:\n    answer='Cat'\nelse:\n    answer='Dog'\nprint(\"The fruit in the image is\",answer)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "The fruit in the image is Cat\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}