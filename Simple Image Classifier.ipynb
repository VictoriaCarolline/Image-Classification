{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#importing all te req lib\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\nfrom keras.preprocessing import image\nimport numpy as np",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# dimensions of our images.\nimg_width, img_height = 150, 150\n\n#defining the data directories\ntrain_data_dir= 'data/train'\nvalidation_data_dir= 'data/validation'\nn_training_sample= 400\nn_validation_sample= 100\nepochs=40\nbatch_size=10",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "if K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#defining the model\nmodel = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)])",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#defining the optimizer and metrics\nmodel.compile(optimizer = tf.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary')\n\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=n_training_sample // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=n_validation_sample // batch_size)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found 800 images belonging to 2 classes.\nFound 200 images belonging to 2 classes.\nEpoch 1/40\n40/40 [==============================] - 430s 11s/step - loss: 0.8042 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 2/40\n40/40 [==============================] - 294s 7s/step - loss: 0.6931 - accuracy: 0.5082 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 3/40\n40/40 [==============================] - 265s 7s/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 4/40\n40/40 [==============================] - 286s 7s/step - loss: 0.6931 - accuracy: 0.4468 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 5/40\n40/40 [==============================] - 269s 7s/step - loss: 0.6931 - accuracy: 0.5270 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 6/40\n40/40 [==============================] - 285s 7s/step - loss: 0.6931 - accuracy: 0.5154 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 7/40\n40/40 [==============================] - 381s 10s/step - loss: 0.6931 - accuracy: 0.5099 - val_loss: 0.6931 - val_accuracy: 0.5000\nEpoch 8/40\n33/40 [=======================>......] - ETA: 35s - loss: 0.6931 - accuracy: 0.4836",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#testing the model\npred= image.load_img('data/test/cat.4000.jpg', target_size=(150,150))\npred=image.img_to_array(pred)\npred= np.expand_dims(pred, axis=0)\nresult= model.predict(pred)\nprint(result)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "if result[0][0]==1:\n    answer='Cat'\nelse:\n    answer='Dog'\nprint(\"The fruit in the image is\",answer)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}